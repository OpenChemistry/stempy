{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm,PowerNorm\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "\n",
    "import stempy.io as stio\n",
    "import stempy.image as stim\n",
    "\n",
    "distiller_path = Path('/global/cfs/projectdirs/ncemhub/distiller/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planeFit(points):\n",
    "    \"\"\"\n",
    "    p, n = planeFit(points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fit an d-dimensional plane to the points.\n",
    "    Return a point, p, on the plane (the point-cloud centroid),\n",
    "    and the normal, n.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n",
    "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
    "    ctr = points.mean(axis=1)\n",
    "    x = points - ctr[:,np.newaxis]\n",
    "    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n",
    "    return ctr, svd(M)[0][:,-1]\n",
    "\n",
    "def get_scan_path(directory, scan_num, scan_id=None, th=None):\n",
    "    \"\"\" Get the file path for a 4D Camaera scan number with \n",
    "    the option of adding the Distiller scan id or the threshold. If scn_id and th\n",
    "    are entered then th is ignored.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : pathlib.Path or str\n",
    "        The path to the directory containing the file.\n",
    "    scan_num : int\n",
    "        The 4D Camera scan number\n",
    "    scan_id : int, optional\n",
    "        The Distiller scan if. Optional\n",
    "    th : float, optional\n",
    "        The threshold for counting. This is added to the filename in some cases.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    : pathlib.Path\n",
    "        The file that matches the input information.\n",
    "    \"\"\"\n",
    "    if scan_num:\n",
    "        if scan_id:\n",
    "            file_path = directory / Path('data_scan{}_id{}_electrons.h5'.format(scan_num, scan_id))\n",
    "        if th:\n",
    "            file_path = directory / Path('data_scan{}_th{}_electrons.h5'.format(scan_num, th))\n",
    "        else:\n",
    "            file_paths = list(directory.glob('data_scan{}*electrons.h5'.format(scan_num, th)))\n",
    "            if len(file_paths) > 1:\n",
    "                raise ValueError('Multiple files match that input. Add scan_id to be more specific.')\n",
    "            else:\n",
    "                file_path = file_paths[0]\n",
    "    else:\n",
    "        raise TypeError('Missing scan_num input.')\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the vacuum scan data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all previous windows to avoid too many windows\n",
    "plt.close('all')\n",
    "\n",
    "# Load a sparse vacuum 4D camera data set \n",
    "date = '2022.07.08'\n",
    "scan_num = 838\n",
    "threshold = 4.5\n",
    "scan_id = 0\n",
    "\n",
    "fname = get_scan_path(distiller_path / Path('counted') / Path(date), scan_num)\n",
    "\n",
    "# Load the data\n",
    "vacuum_scan = stio.SparseArray.from_hdf5(fname)\n",
    "\n",
    "# Remove the flyback\n",
    "vacuum_scan = vacuum_scan[:,:-1,:,:]\n",
    "\n",
    "# Calculate number of electrons per pattern\n",
    "num_elec = 0\n",
    "for ii in vacuum_scan.data:\n",
    "    num_elec += len(ii)\n",
    "avg_elec = num_elec / vacuum_scan.data.shape[0]\n",
    "\n",
    "print('File: {}'.format(fname))\n",
    "print('Initial scan dimensions = {}'.format(vacuum_scan.scan_shape))\n",
    "print('Mean electrons per pattern: {}'.format(avg_elec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the center of the center beam at each scan position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the summed diffraction pattern to set hyperparameters\n",
    "dp = vacuum_scan.sum(axis=(0, 1))\n",
    "\n",
    "# Get a single dense diffraction pattern\n",
    "dp0 = vacuum_scan[10, 10, :, :]\n",
    "\n",
    "# Set the center of the pattern (use figure below for manual)\n",
    "center = stim.com_dense(dp)\n",
    "# center = (270, 285) # manually define as column, row from plot (if automated technique fails)\n",
    "print(f'Initial center = {center}')\n",
    "\n",
    "# Define the radius for iterative processing\n",
    "radius = 40 # pixels\n",
    "\n",
    "fg,ax = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "ax[1].imshow(dp, norm=PowerNorm(0.75))\n",
    "ax[1].scatter(center[0], center[1], c='r')\n",
    "ax[1].add_patch(Circle(center, radius=radius, fc=None, fill=None, ec='r'))\n",
    "ax[0].imshow(dp0, norm=PowerNorm(0.75))\n",
    "ax[0].set(title='single pattern')\n",
    "ax[1].set(title='summed pattern')\n",
    "ax[1].legend(['center of pattern', 'crop_to radius'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the center of mass (COM) iteratively for each scan position\n",
    "com2 = stim.com_sparse(vacuum_scan, crop_to=(radius, radius))\n",
    "com2_median = np.median(com2, axis=(1,2))\n",
    "com2_std = np.std(com2, axis=(1,2))\n",
    "\n",
    "fg,ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(com2[0,]-com2_median[0], vmin=-com2_std[0]*3, vmax=com2_std[0]*3, cmap='bwr')\n",
    "ax[0].set(title='COM: axis 0')\n",
    "ax[1].imshow(com2[1,]-com2_median[1], vmin=-com2_std[1]*3, vmax=com2_std[1]*3, cmap='bwr')\n",
    "ax[1].set(title='COM: axis 1')\n",
    "\n",
    "fg,ax = plt.subplots(1, 2)\n",
    "ax[0].hist(com2[0,].ravel() - com2_median[0])\n",
    "ax[0].set(title='COM: axis 0')\n",
    "ax[1].hist(com2[1,].ravel()-com2_median[1])\n",
    "ax[1].set(title='COM: axis 1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outliers by median filtering\n",
    "com2_filt = np.zeros_like(com2)\n",
    "com2_filt[0,] = ndimage.median_filter(com2[0,], size=(5, 5))\n",
    "com2_filt[1,] = ndimage.median_filter(com2[1,], size=(5, 5))\n",
    "\n",
    "com2_median = np.median(com2_filt, axis=(1, 2))\n",
    "\n",
    "fg,ax = plt.subplots(1, 2,sharex=True,sharey=True)\n",
    "ax[0].imshow(com2_filt[0,]-com2_median[0],cmap='bwr',vmin=-3,vmax=3)\n",
    "ax[0].set(title='COM: axis 0')\n",
    "ax[1].imshow(com2_filt[1,]-com2_median[1],cmap='bwr',vmin=-3,vmax=3);\n",
    "ax[1].set(title='COM: axis 1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the beam motion to reduce noise\n",
    " - If the motion is linear then a plane is sufficient\n",
    " - If the motion is non-linear then use interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate to fit the vacuum scan_shape\n",
    "# This is not exactly necessary, but tests the use of interpolation for later\n",
    "\n",
    "YY, XX = np.mgrid[0:com2.shape[1], 0:com2.shape[2]]\n",
    "\n",
    "# Interpolation\n",
    "com2_fit = np.zeros((2, *XX.shape))\n",
    "com2_fit[0,:,:] = ndimage.map_coordinates(com2_filt[0,:,:], (YY.ravel(), XX.ravel()),mode='nearest').reshape(XX.shape)\n",
    "com2_fit[1,:,:] = ndimage.map_coordinates(com2_filt[1,:,:], (YY.ravel(), XX.ravel()),mode='nearest').reshape(XX.shape)\n",
    "\n",
    "com2_fit_median = np.median(com2_fit,axis=(1,2))\n",
    "\n",
    "# Fit to a plane\n",
    "planeCOM0 = planeFit(np.stack((YY, XX, com2_filt[0,]-com2_median[0])))\n",
    "planeCOM1 = planeFit(np.stack((YY, XX, com2_filt[1,]-com2_median[1])))\n",
    "\n",
    "print(f'plane fit to COM0: {planeCOM0}')\n",
    "print(f'plane fit to COM1: {planeCOM1}')\n",
    "\n",
    "normal = planeCOM0[1]\n",
    "d = np.dot(-planeCOM0[0], normal)\n",
    "# calculate corresponding z\n",
    "z0 = (-normal[0]*YY - normal[1]*XX - d)/normal[2]\n",
    "\n",
    "normal = planeCOM1[1]\n",
    "d = np.dot(-planeCOM1[0], normal)\n",
    "# calculate corresponding z\n",
    "z1 = (-normal[0]*YY - normal[1]*XX - d)/normal[2]\n",
    "\n",
    "# Plot everything together\n",
    "fg,ax = plt.subplots(2, 3)\n",
    "ax[0, 0].imshow(com2_filt[0,],cmap='bwr')\n",
    "ax[0, 0].set(title='Experimental')\n",
    "ax[0, 1].imshow(z0, cmap='bwr')\n",
    "ax[0, 1].set(title='Linear plane fit')\n",
    "ax[1, 0].imshow(com2_filt[1,],cmap='bwr')\n",
    "ax[1, 1].imshow(z1, cmap='bwr')\n",
    "ax[0, 2].imshow(com2_fit[0,]-com2_fit_median[0], cmap='bwr')\n",
    "ax[1, 2].imshow(com2_fit[1,]-com2_fit_median[1], cmap='bwr')\n",
    "ax[0, 2].set(title='Interpolation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove shifts from the vacuum scan to test the fit\n",
    " - Choose the method below according to the type of shift you want to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test centering on the vacuum scan itself\n",
    "method = 'interp' # choose plane or interp\n",
    "\n",
    "if method == 'interp':\n",
    "    scan_origin0 = com2_fit[0,]\n",
    "    scan_origin1 = com2_fit[1,]\n",
    "elif method == 'plane':\n",
    "    scan_origin0 = z0\n",
    "    scan_origin1 = z1\n",
    "scan_origin0_round = np.round(scan_origin0).astype(np.int32) - int(scan_origin0.mean())\n",
    "scan_origin1_round = np.round(scan_origin1).astype(np.int32) - int(scan_origin1.mean())\n",
    "\n",
    "# Ensure the data sets are the same size\n",
    "assert vacuum_scan.data.shape[0] == scan_origin0_round.ravel().shape[0]\n",
    "\n",
    "centered = np.empty_like(vacuum_scan.data)\n",
    "for ii, (eev, x, y) in enumerate(zip(vacuum_scan.data, scan_origin0_round.ravel(), scan_origin1_round.ravel())):\n",
    "    for jj, ev in enumerate(eev):\n",
    "        evx, evy = np.unravel_index(ev, vacuum_scan.frame_shape)\n",
    "        evx_centered = evx - y # need to flip x and y\n",
    "        evy_centered = evy - x\n",
    "\n",
    "        # Some events will get pushed off the detector by the shift. Remove them\n",
    "        keep = (evx_centered < vacuum_scan.frame_shape[0]) & (evx_centered >= 0) & (evy_centered < vacuum_scan.frame_shape[1]) & (evy_centered >= 0)\n",
    "        evx_centered = evx_centered[keep]\n",
    "        evy_centered = evy_centered[keep]\n",
    "\n",
    "        centered[ii, jj] = np.ravel_multi_index((evx_centered,evy_centered), vacuum_scan.frame_shape)\n",
    "\n",
    "vacuum_scan_centered = stio.SparseArray(centered, vacuum_scan.scan_shape, vacuum_scan.frame_shape)\n",
    "\n",
    "dp = vacuum_scan.sum(axis=(0,1))\n",
    "dp2 = vacuum_scan_centered.sum(axis=(0,1))\n",
    "\n",
    "fg,ax = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "ax[0].imshow(dp)\n",
    "ax[0].set(title='Summed raw data')\n",
    "ax[1].imshow(dp2)\n",
    "ax[1].set(title='Summed centered data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the centered vacuum scan to a stempy dataset\n",
    "out_name = fname.with_name('data_scan{}_th{}_electrons_centered.h5'.format(scan_num,threshold))\n",
    "vacuum_scan_centered.write_to_hdf5(out_name)\n",
    "print(out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove beam shift from an experimental data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sparse vacuum 4D camera data set \n",
    "scan_num = 155\n",
    "threshold = 4.5\n",
    "scan_id = 0\n",
    "# data_dir = Path('2021.10.01')\n",
    "\n",
    "fname = Path('/mnt/nvme1/percius/sparse_Si/data_scan{}_th{}_electrons.h5'.format(scan_num, threshold))\n",
    "\n",
    "# Load the data\n",
    "experiment = stio.SparseArray.from_hdf5(fname)\n",
    "experiment = experiment[:,:-1,:,:] # remove flyback\n",
    "\n",
    "print('File: {}'.format(fname))\n",
    "print('Initial scan dimensions = {}'.format(experiment.scan_shape))\n",
    "\n",
    "fg,ax = plt.subplots(1,1)\n",
    "ax.imshow(experiment[::5,::5].sum(axis=(0,1)), norm=PowerNorm(0.25));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate shift correction for the experimental data set\n",
    " - the same method is used (plane or interp)\n",
    " - the experimental data set can have any real space scan shape relative to the vacuum data  set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Using method {method}')\n",
    "\n",
    "# Generate points on the plane to fit the experiment scan_shape\n",
    "factor = (experiment.scan_shape[0] / vacuum_scan.scan_shape[0],\n",
    "          experiment.scan_shape[1] / vacuum_scan.scan_shape[1])\n",
    "\n",
    "# Generate positions between vacuum positions\n",
    "YY, XX = np.mgrid[0:experiment.scan_shape[1], 0:experiment.scan_shape[0]]\n",
    "YY = YY.astype('<f4') / factor[1]\n",
    "XX = XX.astype('<f4') / factor[0]\n",
    "\n",
    "if method == 'interp':\n",
    "    \n",
    "    com2_fit = np.zeros((2, *XX.shape))\n",
    "    com2_fit[0,:,:] = ndimage.map_coordinates(com2_filt[0,:,:], (YY.ravel(), XX.ravel()),mode='nearest').reshape(XX.shape)\n",
    "    com2_fit[1,:,:] = ndimage.map_coordinates(com2_filt[1,:,:], (YY.ravel(), XX.ravel()),mode='nearest').reshape(XX.shape)\n",
    "\n",
    "    com2_fit_median = np.median(com2_fit,axis=(1,2))\n",
    "\n",
    "    z0 = com2_fit[0,:,:]\n",
    "    z1 = com2_fit[1,:,:]\n",
    "elif method == 'plane':\n",
    "    normal = planeCOM0[1]\n",
    "    d = np.dot(-planeCOM0[0], normal)\n",
    "    # calculate corresponding z\n",
    "    z0 = (-normal[0]*YY - normal[1]*XX - d)/normal[2]\n",
    "\n",
    "    normal = planeCOM1[1]\n",
    "    d = np.dot(-planeCOM1[0], normal)\n",
    "    # calculate corresponding z\n",
    "    z1 = (-normal[0]*YY - normal[1]*XX - d)/normal[2]\n",
    "else:\n",
    "    print('unknown method. Choose interp or plane.')\n",
    "    \n",
    "# Round to integers\n",
    "z0_round = np.round(z0 - z0.mean()).astype(np.int64)\n",
    "z1_round = np.round(z1 - z1.mean()).astype(np.int64)\n",
    "\n",
    "# Interpolated data must match experimetnal data shape\n",
    "assert experiment.data.shape[0] == z0_round.ravel().shape[0]\n",
    "assert experiment.data.shape[0] == z1_round.ravel().shape[0]\n",
    "\n",
    "fg,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(z0_round,cmap='bwr')\n",
    "ax[1].imshow(z1_round,cmap='bwr')\n",
    "ax[0].set(title='Pattern shift for axis 0')\n",
    "ax[1].set(title='Pattern shift for axis 1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted plane from the vacuum scan to shift the events\n",
    "\n",
    "centered = np.empty_like(experiment.data)\n",
    "for ii, (eev, x, y) in enumerate(zip(experiment.data, z0_round.ravel(), z1_round.ravel())):\n",
    "    for jj, ev in enumerate(eev):\n",
    "        evx, evy = np.unravel_index(ev, experiment.frame_shape)\n",
    "        evx_centered = evx - y # need to flip x and y\n",
    "        evy_centered = evy - x\n",
    "\n",
    "        # Some events will get pushed off the detector by the shift. Remove them\n",
    "        keep = (evx_centered < experiment.frame_shape[0]) & (evx_centered >= 0) & (evy_centered < experiment.frame_shape[1]) & (evy_centered >= 0)\n",
    "        evx_centered = evx_centered[keep]\n",
    "        evy_centered = evy_centered[keep]\n",
    "\n",
    "        centered[ii, jj] = np.ravel_multi_index((evx_centered,evy_centered), experiment.frame_shape)\n",
    "\n",
    "experiment_centered = stio.SparseArray(centered, experiment.scan_shape, experiment.frame_shape)\n",
    "\n",
    "dp = experiment.sum(axis=(0, 1))\n",
    "dp2 = experiment_centered.sum(axis=(0,1))\n",
    "\n",
    "fg,ax = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "ax[0, 0].imshow(dp, norm=LogNorm())\n",
    "ax[0, 1].imshow(dp2, norm=LogNorm())\n",
    "ax[0, 0].set(title='raw data')\n",
    "ax[1, 0].imshow(dp)\n",
    "ax[1, 1].imshow(dp2)\n",
    "ax[0, 1].set(title='centered data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a stempy dataset\n",
    "out_name = fname.with_name('data_scan{}_th{}_electrons_centered.h5'.format(scan_num,threshold))\n",
    "experiment_centered.write_to_hdf5(out_name)\n",
    "print(out_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stempy-jupyterlab",
   "language": "python",
   "name": "stempy-jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
